{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Text Generation Model for Coherent Paragraphs\n",
                "\n",
                "This notebook demonstrates a text generation model capable of producing coherent paragraphs on specific topics. We leverage the **GPT-2** (Generative Pre-trained Transformer 2) model from Hugging Face for this task.\n",
                "\n",
                "### Key Features:\n",
                "- **Contextual Coherence**: Uses transformer-based architecture to maintain flow.\n",
                "- **Topic Control**: Guided generation based on user-provided prompts.\n",
                "- **Adjustable Parameters**: Control over creativity (temperature) and length."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install necessary libraries\n",
                "!pip install transformers torch"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load the Model\n",
                "\n",
                "We will use `gpt2` as a lightweight and effective baseline. We specify `framework='pt'` to ensure we use PyTorch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import pipeline, set_seed\n",
                "\n",
                "# Initialize the text generation pipeline\n",
                "generator = pipeline('text-generation', model='gpt2', framework='pt')\n",
                "set_seed(42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Generate Coherent Paragraphs\n",
                "\n",
                "We define a function to wrap the generation logic, allowing for easy experimentation with different topics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_paragraph(topic_prompt, max_length=150, temperature=0.7):\n",
                "    \"\"\"\n",
                "    Generates a coherent paragraph based on a topic prompt.\n",
                "    \n",
                "    Args:\n",
                "        topic_prompt (str): The starting sentence or topic.\n",
                "        max_length (int): Maximum number of tokens to generate.\n",
                "        temperature (float): Controls randomness (0.0 to 1.0). Higher = more creative.\n",
                "    \"\"\"\n",
                "    print(f\"Generating content for: '{topic_prompt}'...\\n\")\n",
                "    \n",
                "    results = generator(\n",
                "        topic_prompt, \n",
                "        max_length=max_length, \n",
                "        num_return_sequences=1, \n",
                "        truncation=True,\n",
                "        temperature=temperature,\n",
                "        top_k=50,\n",
                "        top_p=0.95,\n",
                "        pad_token_id=50256\n",
                "    )\n",
                "    \n",
                "    return results[0]['generated_text']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Demonstration on Specific Topics\n",
                "\n",
                "Let's try generating paragraphs for a few different topics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Topic: Artificial Intelligence\n",
                "prompt_ai = \"The future of artificial intelligence in modern healthcare is promising because\"\n",
                "paragraph_ai = generate_paragraph(prompt_ai)\n",
                "print(\"--- AI Topic ---\")\n",
                "print(paragraph_ai)\n",
                "\n",
                "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
                "\n",
                "# Topic: Space Exploration\n",
                "prompt_space = \"Exploring Mars could reveal secrets about the early solar system, such as\"\n",
                "paragraph_space = generate_paragraph(prompt_space)\n",
                "print(\"--- Space Topic ---\")\n",
                "print(paragraph_space)\n",
                "\n",
                "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
                "\n",
                "# Topic: Climate Change\n",
                "prompt_climate = \"Sustainable energy solutions are essential for the planet's survival because\"\n",
                "paragraph_climate = generate_paragraph(prompt_climate)\n",
                "print(\"--- Climate Topic ---\")\n",
                "print(paragraph_climate)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}